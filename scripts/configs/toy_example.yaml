experiment_name: noname
task: toy_example
data:
  batch_size: 50000
  num_workers: 0 #44
model:
  encoder_input_dim: 200
  encoder_hidden_dim: 512
  decoder_input_dim: 64
  decoder_n_layers: 2
  encoder_dropout_p: 0.1
  decoder_dropout_p: 0.1
optimization:
  lr: 0.0001
early_stopping:
  min_delta: 0.0
  patience: 300
checkpointing:
  save_top_k: 1
trainer:
  run_on_gpus: True
  min_epochs: 10000 # 1000
  max_epochs: 100000000 # 30000